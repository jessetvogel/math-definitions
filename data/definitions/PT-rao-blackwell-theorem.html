Let <span class="math inline">\(X_1, \ldots, X_n\)</span> be a <a href="#PT:random-sample">random sample</a> from a population <span class="math inline">\(F_\theta\)</span> depending on some parameter <span class="math inline">\(\theta\)</span>, and write <span class="math inline">\(X = (X_1, \ldots, X_n)\)</span>. Let <span class="math inline">\(W(X)\)</span> be an <a href="#PT:unbiased-estimator">unbiased estimator</a> for some function <span class="math inline">\(\tau(\theta)\)</span> of <span class="math inline">\(\theta\)</span>, and let <span class="math inline">\(T(X)\)</span> be a <a href="#PT:sufficient-statistic">sufficient statistic</a> for <span class="math inline">\(\theta\)</span>. Then the <b>Rao–Blackwell theorem</b> states that <span class="math inline">\(W'(X) = \EE(W(X) \mid T(X))\)</span> is also an unbiased estimator for <span class="math inline">\(\tau(\theta)\)</span>, that is,
<span class="math display">\[ \EE_\theta(W'(X)) = \tau(\theta) \]</span>
with less <a href="#PT:variance">variance</a> than <span class="math inline">\(W(X)\)</span>, that is,
<span class="math display">\[ \operatorname{Var}_\theta(W'(X)) \le \operatorname{Var}_\theta(W(X)) \]</span>
for all <span class="math inline">\(\theta\)</span>. In particular, <span class="math inline">\(W'(X)\)</span> is a ‘uniformly better unbiased estimator’ for <span class="math inline">\(\tau(\theta)\)</span> than <span class="math inline">\(W(X)\)</span>.<br/>
If <span class="math inline">\(T(X)\)</span> is a <a href="#PT:complete-statistic">complete</a> sufficient statistic, then <span class="math inline">\(W'(X) = \EE(W(X) \mid T(X))\)</span> is the unique ‘best’ unbiased estimator, that is, it has the lowest possible variance.
